{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mod2/L2 Formalizing Maximum Likelihood Estimators (MLEs)\n",
    "\n",
    "## Introduction\n",
    "In this lesson, we formalize the concept of Maximum Likelihood Estimators (MLEs). We aim to estimate a parameter $(\\theta)$ from a random sample $(X_1, X_2, \\ldots, X_n)$ that is independent and identically distributed (iid).\n",
    "\n",
    "## Concept\n",
    "The idea behind MLE is to find the value of $(\\theta)$ that makes the observed data most likely. For discrete data, we maximize the joint probability of the observed data. For continuous data, we maximize the probability density function (PDF).\n",
    "\n",
    "## Notation\n",
    "- **Probability Density Function (PDF)**: $( f(x; \\theta) )$\n",
    "- **Joint PDF for the sample**: $( f(X_1, X_2, \\ldots, X_n; \\theta) = \\prod_{i=1}^n f(X_i; \\theta) )$\n",
    "\n",
    "## Steps to Find MLE\n",
    "\n",
    "### 1. Define the Likelihood Function\n",
    "The likelihood function $(L(\\theta))$ is the joint PDF viewed as a function of $(\\theta)$:\n",
    "$$ L(\\theta) = f(X_1, X_2, \\ldots, X_n; \\theta) = \\prod_{i=1}^n f(X_i; \\theta) $$\n",
    "\n",
    "### 2. Log-Likelihood Function\n",
    "To simplify the maximization process, we take the natural logarithm of the likelihood function:\n",
    "$$ \\log L(\\theta) = \\sum_{i=1}^n \\log f(X_i; \\theta) $$\n",
    "\n",
    "### 3. Maximize the Log-Likelihood\n",
    "Find the value of $(\\theta)$ that maximizes the log-likelihood function.\n",
    "\n",
    "## Example: Bernoulli Distribution\n",
    "Suppose we have a random sample from a Bernoulli distribution with parameter $(p)$.\n",
    "\n",
    "#### Likelihood Function\n",
    "$$ L(p) = \\prod_{i=1}^n p^{x_i} (1-p)^{1-x_i} $$\n",
    "\n",
    "#### Log-Likelihood Function\n",
    "$$ \\log L(p) = \\sum_{i=1}^n \\left[ x_i \\log p + (1 - x_i) \\log (1 - p) \\right] $$\n",
    "\n",
    "#### Maximizing the Log-Likelihood\n",
    "To find the MLE for $(p)$, take the derivative of the log-likelihood with respect to $(p)$ and set it to zero:\n",
    "$$ \\frac{d}{dp} \\log L(p) = \\sum_{i=1}^n \\left[ \\frac{x_i}{p} - \\frac{1 - x_i}{1 - p} \\right] = 0 $$\n",
    "\n",
    "Solving for $(p)$, we get:\n",
    "$$ \\hat{p} = \\frac{\\sum_{i=1}^n x_i}{n} $$\n",
    "\n",
    "### Example in R"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.600000005400304"
      ],
      "text/latex": [
       "0.600000005400304"
      ],
      "text/markdown": [
       "0.600000005400304"
      ],
      "text/plain": [
       "[1] 0.6"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Generate a random sample from Bernoulli distribution\n",
    "set.seed(123)\n",
    "n <- 100\n",
    "p_true <- 0.6\n",
    "sample_data <- rbinom(n, size = 1, prob = p_true)\n",
    "\n",
    "# Log-likelihood function\n",
    "log_likelihood <- function(p, data) {\n",
    "  n <- length(data)\n",
    "  logL <- sum(data * log(p) + (1 - data) * log(1 - p))\n",
    "  return(logL)\n",
    "}\n",
    "\n",
    "# Initial guess for p\n",
    "initial_p <- mean(sample_data)\n",
    "\n",
    "# Optimize the log-likelihood\n",
    "optim_result <- optim(initial_p, log_likelihood, data = sample_data, method = \"Brent\", lower = 0, upper = 1, control = list(fnscale = -1))\n",
    "optim_result$par"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "source": [
    "## Example: Exponential Distribution\n",
    "Suppose we have a random sample from the exponential distribution with rate $(\\lambda)$.\n",
    "\n",
    "### Likelihood Function\n",
    "$$ L(\\lambda) = \\lambda^n e^{-\\lambda \\sum X_i} $$\n",
    "\n",
    "### Log-Likelihood Function\n",
    "$$ \\log L(\\lambda) = n \\log \\lambda - \\lambda \\sum X_i $$\n",
    "\n",
    "### Maximizing the Log-Likelihood\n",
    "To find the MLE for $(\\lambda)$, take the derivative of the log-likelihood with respect to $(\\lambda)$ and set it to zero: $$ \\frac{d}{d\\lambda} \\log L(\\lambda) = \\frac{n}{\\lambda} - \\sum X_i = 0 $$ \n",
    "\n",
    "Solving for $(\\lambda)$, we get: \n",
    "$$ \\hat{\\lambda} = \\frac{n}{\\sum X_i} $$\n",
    "\n",
    "#### Example in R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "1.91256024893504"
      ],
      "text/latex": [
       "1.91256024893504"
      ],
      "text/markdown": [
       "1.91256024893504"
      ],
      "text/plain": [
       "[1] 1.91256"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Generate a random sample from Exponential distribution\n",
    "set.seed(123)\n",
    "n <- 100\n",
    "lambda_true <- 2\n",
    "sample_data <- rexp(n, rate = lambda_true)\n",
    "\n",
    "# Log-likelihood function\n",
    "log_likelihood <- function(lambda, data) {\n",
    "  n <- length(data)\n",
    "  logL <- n * log(lambda) - lambda * sum(data)\n",
    "  return(logL)\n",
    "}\n",
    "\n",
    "# Initial guess for lambda\n",
    "initial_lambda <- 1 / mean(sample_data)\n",
    "\n",
    "# Optimize the log-likelihood\n",
    "optim_result <- optim(initial_lambda, log_likelihood, data = sample_data, method = \"Brent\", lower = 0, upper = 10, control = list(fnscale = -1))\n",
    "optim_result$par"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "source": [
    "## Conclusion\n",
    "In this lesson, we formalized the concept of Maximum Likelihood Estimators (MLEs) by defining the likelihood function, taking the log-likelihood, and maximizing it to find the parameter estimates. This method is widely applicable and forms the basis for many statistical analyses.\n",
    "\n",
    "This concludes the formalization of MLEs. In the next lessons (refer to [mod2_summarytranscript_L3_AdvancedMLE.ipynb](mod2_summarytranscript_L3_AdvancedMLE.ipynb)), we will continue to explore more advanced topics and applications of MLE in statistical inference."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
