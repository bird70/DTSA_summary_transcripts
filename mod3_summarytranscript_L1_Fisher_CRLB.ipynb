{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "source": [
    "# Mod3/L1 Cramer-Rao Lower Bound and Fisher Information\n",
    "\n",
    "## Introduction\n",
    "In this module, we discuss the concepts of the Cramer-Rao Lower Bound (CRLB) and Fisher Information. These concepts help evaluate the quality of an estimator, particularly the large sample properties of maximum likelihood estimators (MLEs).\n",
    "\n",
    "## Cramer-Rao Lower Bound (CRLB)\n",
    "The CRLB provides a lower bound on the variance of all unbiased estimators of a function $(\\tau(\\theta))$. It is useful for determining the efficiency of an estimator.\n",
    "\n",
    "### Definition\n",
    "For a random sample $(X_1, X_2, \\ldots, X_n)$ from a distribution with parameter $(\\theta)$, the variance of any unbiased estimator $(\\hat{\\tau})$ of $(\\tau(\\theta))$ is bounded by:\n",
    "$$ \\text{Var}(\\hat{\\tau}) \\geq \\frac{(\\tau'(\\theta))^2}{I_n(\\theta)} $$\n",
    "\n",
    "## Fisher Information\n",
    "The denominator $(I_n(\\theta))$ is known as the Fisher Information, which measures the amount of information that the sample provides about the parameter $(\\theta)$.\n",
    "\n",
    "### Example in R\n",
    "```r\n",
    "# Define the Fisher Information function for a normal distribution\n",
    "fisher_information <- function(n, sigma2) {\n",
    "  return(n / sigma2)\n",
    "}\n",
    "\n",
    "# Parameters\n",
    "n <- 100\n",
    "sigma2 <- 4\n",
    "\n",
    "# Calculate Fisher Information\n",
    "I_n <- fisher_information(n, sigma2)\n",
    "cat(sprintf(\"Fisher Information: %.2f\\n\", I_n))\n",
    "\n",
    "# Calculate Cramer-Rao Lower Bound for the mean (tau(theta) = theta)\n",
    "tau_prime <- 1  # derivative of tau(theta) with respect to theta\n",
    "crlb <- tau_prime^2 / I_n\n",
    "cat(sprintf(\"Cramer-Rao Lower Bound: %.4f\\n\", crlb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fisher Information: 25.00\n",
      "Cramer-Rao Lower Bound: 0.0400\n"
     ]
    }
   ],
   "source": [
    "# Define the Fisher Information function for a normal distribution\n",
    "fisher_information <- function(n, sigma2) {\n",
    "  return(n / sigma2)\n",
    "}\n",
    "\n",
    "# Parameters\n",
    "n <- 100\n",
    "sigma2 <- 4\n",
    "\n",
    "# Calculate Fisher Information\n",
    "I_n <- fisher_information(n, sigma2)\n",
    "cat(sprintf(\"Fisher Information: %.2f\\n\", I_n))\n",
    "\n",
    "# Calculate Cramer-Rao Lower Bound for the mean (tau(theta) = theta)\n",
    "tau_prime <- 1  # derivative of tau(theta) with respect to theta\n",
    "crlb <- tau_prime^2 / I_n\n",
    "cat(sprintf(\"Cramer-Rao Lower Bound: %.4f\\n\", crlb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Proof of the Cramer-Rao Lower Bound\n",
    "The proof of the CRLB is based on the Cauchy-Schwarz inequality. The ***CRLB states that the variance of any unbiased estimator is at least as large as the inverse of the Fisher Information***.\n",
    "\n",
    "### Steps in the Proof\n",
    "**Cauchy-Schwarz Inequality**: $$ \\left( \\int f(x) h(x) , dx \\right)^2 \\leq \\left( \\int f(x)^2 , dx \\right) \\left( \\int h(x)^2 , dx \\right) $$\n",
    "\n",
    "**Expectation Form**: $$ \\left( E[T \\cdot \\frac{\\partial}{\\partial \\theta} \\log f(X; \\theta)] \\right)^2 \\leq E[T^2] \\cdot E\\left[\\left(\\frac{\\partial}{\\partial \\theta} \\log f(X; \\theta)\\right)^2\\right] $$\n",
    "\n",
    "**Fisher Information**: $$ I_n(\\theta) = E\\left[\\left(\\frac{\\partial}{\\partial \\theta} \\log f(X; \\theta)\\right)^2\\right] $$\n",
    "\n",
    "**CRLB**: $$ \\text{Var}(\\hat{\\tau}) \\geq \\frac{(\\tau'(\\theta))^2}{I_n(\\theta)} $$\n",
    "\n",
    "## Example: Bernoulli Distribution\n",
    "Suppose we have a random sample $(X_1, X_2, \\ldots, X_n)$ from a Bernoulli distribution with parameter (p). We want to find the CRLB for (p).\n",
    "\n",
    "### Steps\n",
    "**PDF of Bernoulli Distribution**: $[ f(x; p) = p^x (1-p)^{1-x} ]$\n",
    "\n",
    "**Log-Likelihood**: $[ \\log L(p) = \\sum_{i=1}^n \\left[ x_i \\log p + (1 - x_i) \\log (1 - p) \\right] ]$\n",
    "\n",
    "**Derivative of Log-Likelihood**: $[ \\frac{\\partial}{\\partial p} \\log L(p) = \\sum_{i=1}^n \\left[ \\frac{x_i}{p} - \\frac{1 - x_i}{1 - p} \\right] ]$\n",
    "\n",
    "**Fisher Information**: $[ I_n(p) = \\frac{n}{p(1-p)} ]$\n",
    "\n",
    "**CRLB**: $[ \\text{Var}(\\hat{p}) \\geq \\frac{p(1-p)}{n} ]$\n",
    "\n",
    "#### Example in R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fisher Information: 400.00\n",
      "Cramer-Rao Lower Bound: 0.0025\n"
     ]
    }
   ],
   "source": [
    "# Parameters\n",
    "n <- 100\n",
    "p <- 0.5\n",
    "\n",
    "# Fisher Information for Bernoulli distribution\n",
    "fisher_information_bernoulli <- function(n, p) {\n",
    "  return(n / (p * (1 - p)))\n",
    "}\n",
    "\n",
    "# Calculate Fisher Information\n",
    "I_n <- fisher_information_bernoulli(n, p)\n",
    "cat(sprintf(\"Fisher Information: %.2f\\n\", I_n))\n",
    "\n",
    "# Calculate Cramer-Rao Lower Bound for p\n",
    "tau_prime <- 1  # derivative of tau(p) with respect to p\n",
    "crlb <- tau_prime^2 / I_n\n",
    "cat(sprintf(\"Cramer-Rao Lower Bound: %.4f\\n\", crlb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "The Cramer-Rao Lower Bound (CRLB) and Fisher Information are essential tools for evaluating the efficiency of estimators. The CRLB provides a lower bound on the variance of unbiased estimators, while Fisher Information quantifies the amount of information in the sample about the parameter.\n",
    "\n",
    "This concludes the lesson on the Cramer-Rao Lower Bound and Fisher Information. In the next lessons (refer to [mod3_summarytranscript_L2_computationalSimplificationsFisher.ipynb](mod3_summarytranscript_L2_computationalSimplificationsFisher.ipynb)), we will continue to explore more advanced topics and applications in statistical inference. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
