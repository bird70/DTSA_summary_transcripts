{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "source": [
    "# Mod2/L3 Advanced Maximum Likelihood Estimation (MLE)\n",
    "\n",
    "## Introduction\n",
    "In this lesson, we delve deeper into Maximum Likelihood Estimation (MLE) by exploring two advanced cases:\n",
    "1. When the parameter $(\\theta)$ is higher-dimensional (e.g., a vector of $(\\mu)$ and $(\\sigma^2)$.\n",
    "2. When the parameter is involved in defining the support of the distribution.\n",
    "\n",
    "## Case 1: Higher-Dimensional Parameter\n",
    "\n",
    "### Example: Normal Distribution\n",
    "Suppose we have a random sample $(X_1, X_2, \\ldots, X_n)$ from a normal distribution with mean $(\\mu)$ and variance $(\\sigma^2)$.\n",
    "\n",
    "#### Joint PDF\n",
    "The joint PDF for the sample is:\n",
    "$[ f(X_1, X_2, \\ldots, X_n; \\mu, \\sigma^2) = \\left( \\frac{1}{\\sqrt{2\\pi\\sigma^2}} \\right)^n \\exp \\left( -\\frac{1}{2\\sigma^2} \\sum_{i=1}^n (X_i - \\mu)^2 \\right) ]$\n",
    "\n",
    "#### Log-Likelihood\n",
    "To simplify the maximization process, we take the natural logarithm of the likelihood function:\n",
    "$[ \\log L(\\mu, \\sigma^2) = -\\frac{n}{2} \\log(2\\pi\\sigma^2) - \\frac{1}{2\\sigma^2} \\sum_{i=1}^n (X_i - \\mu)^2 ]$\n",
    "\n",
    "#### Maximizing the Log-Likelihood\n",
    "We maximize the log-likelihood with respect to $(\\mu)$ and $(\\sigma^2)$.\n",
    "\n",
    "### Example in R\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>5.18073955338382</li><li>3.29999940014682</li></ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 5.18073955338382\n",
       "\\item 3.29999940014682\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 5.18073955338382\n",
       "2. 3.29999940014682\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 5.180740 3.299999"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Generate a random sample from Normal distribution\n",
    "set.seed(123)\n",
    "n <- 100\n",
    "mu_true <- 5\n",
    "sigma_true <- 2\n",
    "sample_data <- rnorm(n, mean = mu_true, sd = sigma_true)\n",
    "\n",
    "# Log-likelihood function\n",
    "log_likelihood <- function(params, data) {\n",
    "  mu <- params[1]\n",
    "  sigma2 <- params[2]\n",
    "  n <- length(data)\n",
    "  logL <- -n/2 * log(2 * pi * sigma2) - 1/(2 * sigma2) * sum((data - mu)^2)\n",
    "  return(logL)\n",
    "}\n",
    "\n",
    "# Initial guesses for mu and sigma^2\n",
    "initial_params <- c(mean(sample_data), var(sample_data))\n",
    "\n",
    "# Optimize the log-likelihood\n",
    "optim_result <- optim(initial_params, log_likelihood, data = sample_data, control = list(fnscale = -1))\n",
    "optim_result$par"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case 2: Parameter in the Support\n",
    "\n",
    "### Example: Uniform Distribution\n",
    "Suppose $(X \\sim \\text{Uniform}(0, \\theta))$. The PDF is: $[ f(x; \\theta) = \\begin{cases} \\frac{1}{\\theta} & \\text{if } 0 \\leq x \\leq \\theta \\ 0 & \\text{otherwise} \\end{cases} ]$\n",
    "\n",
    "### Likelihood Function\n",
    "For a sample $(X_1, X_2, \\ldots, X_n)$, the likelihood function is: $[ L(\\theta) = \\begin{cases} \\frac{1}{\\theta^n} & \\text{if } \\theta \\geq \\max(X_1, X_2, \\ldots, X_n) \\ 0 & \\text{otherwise} \\end{cases} ]$\n",
    "\n",
    "### Maximizing the Likelihood\n",
    "The MLE for $(\\theta)$ is the maximum observed value in the sample: $[ \\hat{\\theta} = \\max(X_1, X_2, \\ldots, X_n) ]$\n",
    "\n",
    "#### Example in R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The MLE for theta is: 9.94\n"
     ]
    }
   ],
   "source": [
    "# Generate a random sample from Uniform distribution\n",
    "set.seed(123)\n",
    "n <- 100\n",
    "theta_true <- 10\n",
    "sample_data <- runif(n, min = 0, max = theta_true)\n",
    "\n",
    "# MLE for theta\n",
    "theta_hat <- max(sample_data)\n",
    "cat(sprintf(\"The MLE for theta is: %.2f\\n\", theta_hat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "In this lesson, we explored advanced cases of Maximum Likelihood Estimation (MLE), including higher-dimensional parameters and parameters involved in the support of the distribution. Understanding these cases enhances our ability to apply MLE to a wide range of statistical problems.\n",
    "\n",
    "This concludes the advanced MLE lesson. In the next lessons (refer to [mod2_summarytranscript_L4_Invariance_in_MLE.ipynb](mod2_summarytranscript_L4_Invariance_in_MLE.ipynb)), we will continue to explore more complex applications and techniques in statistical inference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
