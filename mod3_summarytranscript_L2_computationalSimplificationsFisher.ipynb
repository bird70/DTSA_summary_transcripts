{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mod3/L2 Computational Simplifications for Fisher Information and Cramer-Rao Lower Bound\n",
    "\n",
    "## Introduction\n",
    "In this lesson, we discuss useful computational simplifications for calculating the Fisher Information and the Cramer-Rao Lower Bound (CRLB). These simplifications make it easier to evaluate the quality of an estimator.\n",
    "\n",
    "## Fisher Information\n",
    "The Fisher Information measures the amount of information that a sample provides about a parameter $(\\theta)$.\n",
    "\n",
    "### Simplification 1: Score Function\n",
    "The expectation of the score function (the derivative of the log of the joint PDF) is zero:\n",
    "$[ E\\left[\\frac{\\partial}{\\partial \\theta} \\log f(X; \\theta)\\right] = 0 ]$\n",
    "\n",
    "### Simplification 2: Second Derivative\n",
    "Instead of squaring the score function and taking the expectation, you can use the second derivative of the log-likelihood:\n",
    "$[ I_n(\\theta) = -E\\left[\\frac{\\partial^2}{\\partial \\theta^2} \\log f(X; \\theta)\\right] ]$\n",
    "\n",
    "### Simplification 3: IID Data\n",
    "For independent and identically distributed (iid) data, the Fisher Information for a sample of size $(n)$ is $(n)$ times the Fisher Information for a sample of size 1:\n",
    "$[ I_n(\\theta) = n \\cdot I_1(\\theta) ]$\n",
    "\n",
    "## Example: Exponential Distribution\n",
    "Suppose we have a random sample from the exponential distribution with rate $(\\lambda)$. We want to find the CRLB for the variance of all unbiased estimators of $(\\lambda)$.\n",
    "\n",
    "### Steps\n",
    "1. **PDF of Exponential Distribution**:\n",
    "   $[ f(x; \\lambda) = \\lambda e^{-\\lambda x} ]$\n",
    "\n",
    "2. **Log-Likelihood**:\n",
    "   $[ \\log L(\\lambda) = n \\log \\lambda - \\lambda \\sum_{i=1}^n x_i ]$\n",
    "\n",
    "3. **First Derivative**:\n",
    "   $[ \\frac{\\partial}{\\partial \\lambda} \\log L(\\lambda) = \\frac{n}{\\lambda} - \\sum_{i=1}^n x_i ]$\n",
    "\n",
    "4. **Second Derivative**:\n",
    "   $[ \\frac{\\partial^2}{\\partial \\lambda^2} \\log L(\\lambda) = -\\frac{n}{\\lambda^2} ]$\n",
    "\n",
    "5. **Fisher Information**:\n",
    "   $[ I_n(\\lambda) = -E\\left[\\frac{\\partial^2}{\\partial \\lambda^2} \\log L(\\lambda)\\right] = \\frac{n}{\\lambda^2} ]$\n",
    "   \n",
    "6. **CRLB**:\n",
    "   $[ \\text{Var}(\\hat{\\lambda}) \\geq \\frac{\\lambda^2}{n} ]$\n",
    "\n",
    "### Example in R\n",
    "```r\n",
    "# Generate a random sample from Exponential distribution\n",
    "set.seed(123)\n",
    "n <- 100\n",
    "lambda_true <- 2\n",
    "sample_data <- rexp(n, rate = lambda_true)\n",
    "\n",
    "# Log-likelihood function\n",
    "log_likelihood <- function(lambda, data) {\n",
    "  n <- length(data)\n",
    "  logL <- n * log(lambda) - lambda * sum(data)\n",
    "  return(logL)\n",
    "}\n",
    "\n",
    "# First derivative of log-likelihood\n",
    "first_derivative <- function(lambda, data) {\n",
    "  n <- length(data)\n",
    "  return(n / lambda - sum(data))\n",
    "}\n",
    "\n",
    "# Second derivative of log-likelihood\n",
    "second_derivative <- function(lambda, data) {\n",
    "  n <- length(data)\n",
    "  return(-n / lambda^2)\n",
    "}\n",
    "\n",
    "# Calculate Fisher Information\n",
    "fisher_information <- function(lambda, data) {\n",
    "  return(-mean(second_derivative(lambda, data)))\n",
    "}\n",
    "\n",
    "# Calculate CRLB\n",
    "lambda_hat <- 1 / mean(sample_data)\n",
    "I_n <- fisher_information(lambda_hat, sample_data)\n",
    "crlb <- lambda_hat^2 / n\n",
    "cat(sprintf(\"Cramer-Rao Lower Bound: %.4f\\n\", crlb))\n",
    "```\n",
    "\n",
    "\n",
    "## Conclusion\n",
    "In this lesson, we explored computational simplifications for calculating the Fisher Information and the Cramer-Rao Lower Bound (CRLB). These simplifications make it easier to evaluate the efficiency of estimators. Understanding these concepts is crucial for advanced statistical inference.\n",
    "\n",
    "This concludes the lesson on computational simplifications for Fisher Information and CRLB. In the next lessons (refer to [mod2_summarytranscript_L1_MaximumLikelihoodMLE.ipynb](mod3_summarytranscript_L3_weakLawLargeNumbers.ipynb)), we will continue to explore more advanced topics and applications in statistical inference. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### R Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cramer-Rao Lower Bound: 0.0366\n"
     ]
    }
   ],
   "source": [
    "# Generate a random sample from Exponential distribution\n",
    "set.seed(123)\n",
    "n <- 100\n",
    "lambda_true <- 2\n",
    "sample_data <- rexp(n, rate = lambda_true)\n",
    "\n",
    "# Log-likelihood function\n",
    "log_likelihood <- function(lambda, data) {\n",
    "  n <- length(data)\n",
    "  logL <- n * log(lambda) - lambda * sum(data)\n",
    "  return(logL)\n",
    "}\n",
    "\n",
    "# First derivative of log-likelihood\n",
    "first_derivative <- function(lambda, data) {\n",
    "  n <- length(data)\n",
    "  return(n / lambda - sum(data))\n",
    "}\n",
    "\n",
    "# Second derivative of log-likelihood\n",
    "second_derivative <- function(lambda, data) {\n",
    "  n <- length(data)\n",
    "  return(-n / lambda^2)\n",
    "}\n",
    "\n",
    "# Calculate Fisher Information\n",
    "fisher_information <- function(lambda, data) {\n",
    "  return(-mean(second_derivative(lambda, data)))\n",
    "}\n",
    "\n",
    "# Calculate CRLB\n",
    "lambda_hat <- 1 / mean(sample_data)\n",
    "I_n <- fisher_information(lambda_hat, sample_data)\n",
    "crlb <- lambda_hat^2 / n\n",
    "cat(sprintf(\"Cramer-Rao Lower Bound: %.4f\\n\", crlb))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
